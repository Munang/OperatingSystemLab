{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Adrd', 'BaseBridge', 'DroidDream', 'DroidKungFu', 'ExploitLinuxLotoor', 'FakeDoc', 'FakeInstaller', 'FakeRun', 'Gappusin', 'Geinimi', 'GinMaster', 'Glodream', 'Iconosys', 'Imlog', 'Kmin', 'MobileTx', 'Opfake', 'Plankton', 'SendPay', 'SMSreg']\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os, glob, numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "\n",
    "caltech_dir = \"D:\\\\Drebin\\\\dex_exper\\\\dex_dataset_20\"\n",
    "\n",
    "categories =[]\n",
    "\n",
    "with open(\"D:\\\\Drebin\\\\\\\\fam_20.txt\",\"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        categories.append(line.split('\\n')[0])\n",
    "    \n",
    "nb_classes = len(categories)\n",
    "print(categories)   \n",
    "\n",
    "image_w = 64\n",
    "image_h = 64\n",
    "\n",
    "pixels = image_h * image_w\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for idx, cat in enumerate(categories):\n",
    "    \n",
    "    #one-hot 돌리기.\n",
    "    label = [0 for i in range(nb_classes)]\n",
    "    label[idx] = 1\n",
    "\n",
    "    image_dir = caltech_dir + \"\\\\\" + cat + \"\\\\\"\n",
    "    files = glob.glob(image_dir+\"*.jpg\")\n",
    "        \n",
    "    for i, f in enumerate(files):\n",
    "        img = Image.open(f)\n",
    "        img = img.convert(\"L\")\n",
    "        img = img.resize((image_w, image_h))\n",
    "        data = np.asarray(img)\n",
    "\n",
    "        X.append(data)\n",
    "        y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok 4639\n"
     ]
    }
   ],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,stratify=y,test_size=0.2,random_state =42)\n",
    "xy = (X_train, X_test, y_train, y_test)\n",
    "np.save(\"D:\\\\Drebin\\\\dex_exper\\\\multi_code_data.npy20\", xy)\n",
    "\n",
    "print(\"ok\", len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0],64,64, 1).astype('float32') / 255\n",
    "X_test = X_test.reshape(X_test.shape[0], 64, 64, 1).astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,Conv3D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.backend.tensorflow_backend as K\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import optimizers\n",
    "from keras.utils import np_utils\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with K.tf_ops.device('/device:GPU:0'):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, kernel_size=(3,3), input_shape = (64,64,1), activation='relu'))\n",
    "    model.add(Conv2D(128, (3,3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(Conv2D(128, (3,3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Conv2D(150, (3,3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(20, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='Adamax', metrics=['accuracy'])\n",
    "    \n",
    "    model_dir = './model/'\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.mkdir(model_dir)\n",
    "    \n",
    "    modelName = model_dir + 'cnn_mnist.model'\n",
    "    \n",
    "    checkpointer = ModelCheckpoint(filepath=modelName, monitor='val_loss', verbose=1, save_best_only = True)\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3154 samples, validate on 557 samples\n",
      "Epoch 1/100\n",
      "3154/3154 [==============================] - 3s 894us/step - loss: 2.3152 - accuracy: 0.2854 - val_loss: 2.0086 - val_accuracy: 0.3698\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.00858, saving model to ./model/cnn_mnist.model\n",
      "Epoch 2/100\n",
      "3154/3154 [==============================] - 3s 826us/step - loss: 1.7412 - accuracy: 0.4876 - val_loss: 1.4863 - val_accuracy: 0.6050\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.00858 to 1.48625, saving model to ./model/cnn_mnist.model\n",
      "Epoch 3/100\n",
      "3154/3154 [==============================] - 3s 826us/step - loss: 1.3604 - accuracy: 0.6240 - val_loss: 1.2245 - val_accuracy: 0.6661\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.48625 to 1.22448, saving model to ./model/cnn_mnist.model\n",
      "Epoch 4/100\n",
      "3154/3154 [==============================] - 3s 820us/step - loss: 1.1564 - accuracy: 0.6782 - val_loss: 1.0777 - val_accuracy: 0.7038\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.22448 to 1.07773, saving model to ./model/cnn_mnist.model\n",
      "Epoch 5/100\n",
      "3154/3154 [==============================] - 3s 822us/step - loss: 0.9984 - accuracy: 0.7257 - val_loss: 0.9503 - val_accuracy: 0.7415\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.07773 to 0.95028, saving model to ./model/cnn_mnist.model\n",
      "Epoch 6/100\n",
      "3154/3154 [==============================] - 3s 831us/step - loss: 0.9160 - accuracy: 0.7416 - val_loss: 0.9041 - val_accuracy: 0.7684\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.95028 to 0.90406, saving model to ./model/cnn_mnist.model\n",
      "Epoch 7/100\n",
      "3154/3154 [==============================] - 3s 816us/step - loss: 0.8172 - accuracy: 0.7796 - val_loss: 0.8145 - val_accuracy: 0.7846\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.90406 to 0.81446, saving model to ./model/cnn_mnist.model\n",
      "Epoch 8/100\n",
      "3154/3154 [==============================] - 3s 822us/step - loss: 0.7537 - accuracy: 0.7888 - val_loss: 0.7636 - val_accuracy: 0.8061\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.81446 to 0.76356, saving model to ./model/cnn_mnist.model\n",
      "Epoch 9/100\n",
      "3154/3154 [==============================] - 3s 822us/step - loss: 0.6874 - accuracy: 0.8120 - val_loss: 0.6787 - val_accuracy: 0.8115\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.76356 to 0.67868, saving model to ./model/cnn_mnist.model\n",
      "Epoch 10/100\n",
      "3154/3154 [==============================] - 3s 822us/step - loss: 0.6303 - accuracy: 0.8228 - val_loss: 0.6187 - val_accuracy: 0.8384\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.67868 to 0.61865, saving model to ./model/cnn_mnist.model\n",
      "Epoch 11/100\n",
      "3154/3154 [==============================] - 3s 818us/step - loss: 0.5871 - accuracy: 0.8345 - val_loss: 0.6629 - val_accuracy: 0.8097\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.61865\n",
      "Epoch 12/100\n",
      "3154/3154 [==============================] - 3s 823us/step - loss: 0.5500 - accuracy: 0.8424 - val_loss: 0.6132 - val_accuracy: 0.8223\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.61865 to 0.61319, saving model to ./model/cnn_mnist.model\n",
      "Epoch 13/100\n",
      "3154/3154 [==============================] - 3s 818us/step - loss: 0.4951 - accuracy: 0.8519 - val_loss: 0.5841 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.61319 to 0.58412, saving model to ./model/cnn_mnist.model\n",
      "Epoch 14/100\n",
      "3154/3154 [==============================] - 3s 825us/step - loss: 0.4881 - accuracy: 0.8586 - val_loss: 0.5234 - val_accuracy: 0.8689\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.58412 to 0.52338, saving model to ./model/cnn_mnist.model\n",
      "Epoch 15/100\n",
      "3154/3154 [==============================] - 3s 803us/step - loss: 0.4644 - accuracy: 0.8592 - val_loss: 0.5221 - val_accuracy: 0.8743\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.52338 to 0.52209, saving model to ./model/cnn_mnist.model\n",
      "Epoch 16/100\n",
      "3154/3154 [==============================] - 3s 801us/step - loss: 0.4189 - accuracy: 0.8776 - val_loss: 0.4981 - val_accuracy: 0.8815\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.52209 to 0.49808, saving model to ./model/cnn_mnist.model\n",
      "Epoch 17/100\n",
      "3154/3154 [==============================] - 3s 827us/step - loss: 0.3998 - accuracy: 0.8821 - val_loss: 0.4898 - val_accuracy: 0.8779\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.49808 to 0.48981, saving model to ./model/cnn_mnist.model\n",
      "Epoch 18/100\n",
      "3154/3154 [==============================] - 3s 822us/step - loss: 0.3769 - accuracy: 0.8865 - val_loss: 0.4852 - val_accuracy: 0.8779\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.48981 to 0.48519, saving model to ./model/cnn_mnist.model\n",
      "Epoch 19/100\n",
      "3154/3154 [==============================] - 3s 818us/step - loss: 0.3562 - accuracy: 0.8925 - val_loss: 0.4706 - val_accuracy: 0.8887\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.48519 to 0.47055, saving model to ./model/cnn_mnist.model\n",
      "Epoch 20/100\n",
      "3154/3154 [==============================] - 3s 823us/step - loss: 0.3414 - accuracy: 0.9004 - val_loss: 0.4766 - val_accuracy: 0.8761\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.47055\n",
      "Epoch 21/100\n",
      "3154/3154 [==============================] - 3s 822us/step - loss: 0.3302 - accuracy: 0.9011 - val_loss: 0.4515 - val_accuracy: 0.8923\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.47055 to 0.45145, saving model to ./model/cnn_mnist.model\n",
      "Epoch 22/100\n",
      "3154/3154 [==============================] - 3s 846us/step - loss: 0.3250 - accuracy: 0.9042 - val_loss: 0.4873 - val_accuracy: 0.8815\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.45145\n",
      "Epoch 23/100\n",
      "3154/3154 [==============================] - 3s 828us/step - loss: 0.2860 - accuracy: 0.9134 - val_loss: 0.4629 - val_accuracy: 0.8905\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.45145\n",
      "Epoch 24/100\n",
      "3154/3154 [==============================] - 3s 831us/step - loss: 0.2844 - accuracy: 0.9122 - val_loss: 0.4522 - val_accuracy: 0.8851\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.45145\n",
      "Epoch 25/100\n",
      "3154/3154 [==============================] - 3s 824us/step - loss: 0.2621 - accuracy: 0.9172 - val_loss: 0.4431 - val_accuracy: 0.8887\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.45145 to 0.44309, saving model to ./model/cnn_mnist.model\n",
      "Epoch 26/100\n",
      "3154/3154 [==============================] - 3s 808us/step - loss: 0.2685 - accuracy: 0.9207 - val_loss: 0.4280 - val_accuracy: 0.9013\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.44309 to 0.42803, saving model to ./model/cnn_mnist.model\n",
      "Epoch 27/100\n",
      "3154/3154 [==============================] - 3s 825us/step - loss: 0.2466 - accuracy: 0.9236 - val_loss: 0.4385 - val_accuracy: 0.8923\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.42803\n",
      "Epoch 28/100\n",
      "3154/3154 [==============================] - 3s 819us/step - loss: 0.2322 - accuracy: 0.9242 - val_loss: 0.4939 - val_accuracy: 0.8869\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.42803\n",
      "Epoch 29/100\n",
      "3154/3154 [==============================] - 3s 824us/step - loss: 0.2158 - accuracy: 0.9233 - val_loss: 0.4467 - val_accuracy: 0.8941\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.42803\n",
      "Epoch 30/100\n",
      "3154/3154 [==============================] - 3s 827us/step - loss: 0.2268 - accuracy: 0.9258 - val_loss: 0.4766 - val_accuracy: 0.8941\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.42803\n",
      "Epoch 31/100\n",
      "3154/3154 [==============================] - 3s 828us/step - loss: 0.2103 - accuracy: 0.9321 - val_loss: 0.4976 - val_accuracy: 0.8959\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.42803\n",
      "Epoch 32/100\n",
      "3154/3154 [==============================] - 3s 822us/step - loss: 0.1960 - accuracy: 0.9410 - val_loss: 0.4877 - val_accuracy: 0.8995\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.42803\n",
      "Epoch 33/100\n",
      "3154/3154 [==============================] - 3s 827us/step - loss: 0.1890 - accuracy: 0.9420 - val_loss: 0.4137 - val_accuracy: 0.8995\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.42803 to 0.41369, saving model to ./model/cnn_mnist.model\n",
      "Epoch 34/100\n",
      "3154/3154 [==============================] - 3s 820us/step - loss: 0.1719 - accuracy: 0.9445 - val_loss: 0.4677 - val_accuracy: 0.8977\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.41369\n",
      "Epoch 35/100\n",
      "3154/3154 [==============================] - 3s 852us/step - loss: 0.1879 - accuracy: 0.9407 - val_loss: 0.4962 - val_accuracy: 0.8995\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.41369\n",
      "Epoch 36/100\n",
      "3154/3154 [==============================] - 3s 868us/step - loss: 0.1756 - accuracy: 0.9439 - val_loss: 0.4677 - val_accuracy: 0.8977\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.41369\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3154/3154 [==============================] - 3s 875us/step - loss: 0.1694 - accuracy: 0.9423 - val_loss: 0.4654 - val_accuracy: 0.9013\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.41369\n",
      "Epoch 38/100\n",
      "3154/3154 [==============================] - 3s 836us/step - loss: 0.1505 - accuracy: 0.9540 - val_loss: 0.4917 - val_accuracy: 0.9013\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.41369\n",
      "Epoch 39/100\n",
      "3154/3154 [==============================] - 3s 841us/step - loss: 0.1600 - accuracy: 0.9524 - val_loss: 0.4324 - val_accuracy: 0.9031\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.41369\n",
      "Epoch 40/100\n",
      "3154/3154 [==============================] - 3s 846us/step - loss: 0.1408 - accuracy: 0.9537 - val_loss: 0.4538 - val_accuracy: 0.9013\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.41369\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=100, batch_size=10, validation_split = 0.15, callbacks=[early_stopping, checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.56      0.67        18\n",
      "           1       0.96      0.80      0.87        65\n",
      "           2       0.92      0.75      0.83        16\n",
      "           3       0.88      0.91      0.90       133\n",
      "           4       0.75      0.46      0.57        13\n",
      "           5       0.96      0.88      0.92        26\n",
      "           6       0.98      0.98      0.98       185\n",
      "           7       0.80      1.00      0.89        12\n",
      "           8       0.89      0.67      0.76        12\n",
      "           9       0.54      0.78      0.64        18\n",
      "          10       0.69      0.81      0.74        68\n",
      "          11       0.60      0.43      0.50        14\n",
      "          12       0.94      0.97      0.95        31\n",
      "          13       1.00      1.00      1.00         9\n",
      "          14       0.91      1.00      0.95        29\n",
      "          15       1.00      1.00      1.00        14\n",
      "          16       0.97      0.97      0.97       120\n",
      "          17       0.96      0.97      0.96       125\n",
      "          18       1.00      0.92      0.96        12\n",
      "          19       0.60      0.75      0.67         8\n",
      "\n",
      "    accuracy                           0.90       928\n",
      "   macro avg       0.86      0.83      0.84       928\n",
      "weighted avg       0.91      0.90      0.90       928\n",
      "\n",
      "[[ 10   0   0   3   0   0   0   1   0   1   3   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0  52   0   2   0   0   1   0   0   4   3   2   0   0   0   0   0   1\n",
      "    0   0]\n",
      " [  1   0  12   0   0   1   0   0   0   0   0   0   0   0   1   0   1   0\n",
      "    0   0]\n",
      " [  0   1   0 121   1   0   0   0   1   2   6   0   0   0   0   0   0   0\n",
      "    0   1]\n",
      " [  0   0   0   0   6   0   1   0   0   0   3   1   0   0   0   0   0   0\n",
      "    0   2]\n",
      " [  0   0   0   0   0  23   0   1   0   0   0   0   0   0   2   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   1   1   0 182   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   1]\n",
      " [  0   0   0   0   0   0   0  12   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   3   0   0   0   0   8   0   0   0   0   0   0   0   0   1\n",
      "    0   0]\n",
      " [  1   0   0   0   0   0   0   0   0  14   3   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   1   3   0   0   0   0   0   5  55   1   0   0   0   0   0   3\n",
      "    0   0]\n",
      " [  0   0   0   2   0   0   0   0   0   0   5   6   0   0   0   0   1   0\n",
      "    0   0]\n",
      " [  0   1   0   0   0   0   0   0   0   0   0   0  30   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   9   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  29   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  14   0   0\n",
      "    0   0]\n",
      " [  0   0   0   1   0   0   2   0   0   0   0   0   1   0   0   0 116   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   0   1 121\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0\n",
      "   11   0]\n",
      " [  0   0   0   1   0   0   0   1   0   0   0   0   0   0   0   0   0   0\n",
      "    0   6]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_test_class = np.argmax(y_test,axis=1)\n",
    "y_pred_class = np.argmax(y_pred,axis=1)\n",
    "\n",
    "print(classification_report(y_test_class,y_pred_class))\n",
    "print(confusion_matrix(y_test_class,y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.optimizers import RMSprop, Adadelta, Nadam, Adagrad, SGD, Adam\n",
    "opt = RMSprop()\n",
    "with K.tf_ops.device('/device:GPU:0'):\n",
    "    model = InceptionV3(weights=None, include_top=True, classes=20)\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "    model_dir = './model/'\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.mkdir(model_dir)\n",
    "\n",
    "    modelName = model_dir + 'cnn_mnist.model'\n",
    "    checkpointer = ModelCheckpoint(filepath=modelName, monitor='val_loss', verbose=1, save_best_only = True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, epochs=100, batch_size=20,validation_split = 0.2, callbacks=[early_stopping, checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.39      0.50        18\n",
      "           1       1.00      0.80      0.89        65\n",
      "           2       0.86      0.75      0.80        16\n",
      "           3       0.75      0.82      0.78       133\n",
      "           4       0.10      0.08      0.09        13\n",
      "           5       0.89      0.96      0.93        26\n",
      "           6       0.96      0.74      0.84       185\n",
      "           7       1.00      0.92      0.96        12\n",
      "           8       0.53      0.75      0.62        12\n",
      "           9       0.87      0.72      0.79        18\n",
      "          10       0.83      0.56      0.67        68\n",
      "          11       0.22      0.29      0.25        14\n",
      "          12       0.36      0.94      0.52        31\n",
      "          13       0.73      0.89      0.80         9\n",
      "          14       0.94      1.00      0.97        29\n",
      "          15       0.93      0.93      0.93        14\n",
      "          16       0.91      0.96      0.93       120\n",
      "          17       0.89      0.96      0.92       125\n",
      "          18       1.00      1.00      1.00        12\n",
      "          19       0.78      0.88      0.82         8\n",
      "\n",
      "    accuracy                           0.81       928\n",
      "   macro avg       0.76      0.77      0.75       928\n",
      "weighted avg       0.84      0.81      0.81       928\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_test_class = np.argmax(y_test,axis=1)\n",
    "y_pred_class = np.argmax(y_pred,axis=1)\n",
    "print(classification_report(y_test_class,y_pred_class))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
